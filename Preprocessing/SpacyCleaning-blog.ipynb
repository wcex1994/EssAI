{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/haileywu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blog information: (681284, 7)\n"
     ]
    }
   ],
   "source": [
    "dirname = '../Dataset_v3/blog/blogtext.csv'\n",
    "blog = pd.read_csv(dirname)\n",
    "print(\"blog information: {0}\".format(blog.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog = blog[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog['wordlength'] = blog['text'].str.split().str.len() >= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_f = blog[blog['wordlength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_f = blog_f[['text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474726</th>\n",
       "      <td>Dear Susan,  There once was a bird the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474727</th>\n",
       "      <td>Dear Susan, you keep asking me who your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474728</th>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474729</th>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474730</th>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474731 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0                  In het kader van kernfusie op aarde...\n",
       "1                    Thanks to Yahoo!'s Toolbar I can ...\n",
       "2                    I had an interesting conversation...\n",
       "3                    Somehow Coca-Cola has a way of su...\n",
       "4                    If anything, Korea is a country o...\n",
       "...                                                   ...\n",
       "474726         Dear Susan,  There once was a bird the ...\n",
       "474727         Dear Susan, you keep asking me who your...\n",
       "474728         Dear Susan,  'I have the second yeast i...\n",
       "474729         Dear Susan:    Just to clarify, I am as...\n",
       "474730         Hey everybody...and Susan,  You might a...\n",
       "\n",
       "[474731 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     474731\n",
       "unique         1\n",
       "top            0\n",
       "freq      474731\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_f['Label'] = \"0\"\n",
    "blog_f = blog_f[['text','Label']]\n",
    "\n",
    "print(blog_f.shape[0])\n",
    "blog_f.Label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_f = blog_f[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply on the df['Text']\n",
    "# retain all columns and add addtional columns spacy_words\n",
    "def NER_replace(df):\n",
    "    df['spacy_words'] = df['text'].apply(lambda x: list(nlp(x).ents))\n",
    "    for index, row in df.iterrows():\n",
    "        thistext = row.text\n",
    "        for ent in row.spacy_words:\n",
    "            if ent.label_ in ['PERSON','FAC','GPE','LOC','ORG']:\n",
    "                thistext = thistext.replace(ent.text,ent.label_)\n",
    "        df.at[index, 'text'] = thistext\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_f1 = NER_replace(blog_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"             PERSON has a way of summing up things so well.  In the early 1970s they had as their flagship jingle 'I'd Like to Buy the World a ORG' (to the tune of 'I'd Like to Teach the World to Sing') that pretty much summed up the post-Woodstock era so well.  It didn't add much to sales, but it was a catchy tune.  In GPE ORG's theme is  urlLink Stop Thinking. Feel it.  which pretty much sums up a lot about GPE and GPEns.  (Look at how relaxed that couple is, now that they stopped thinking and started feeling.) Of course they have a high regard for education and math and logic and such, but deep down I think many GPEns really like to work on emotion more than anything else.  Westerners seem to sublimate this moreso, or at least display it in a different way.  Maybe scratch all that...Westerners and GPEns are probably pretty similar, but the context in which we do it is different.  Anyways, if you think you're losing it in GPE just repeat to yourself 'Stop thinking, feel it. Stop thinking, feel it. Stop thinking, feel it.' and everything will be alright.         \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_f1.text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somehow Coca-Cola 13 30 PERSON\n",
      "Coke 154 158 ORG\n",
      "Coke 340 344 ORG\n",
      "Korea 428 433 GPE\n",
      "Korea 961 966 GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in blog_f1.spacy_words[3]:\n",
    "    if ent.label_ in ['PERSON','FAC','GPE','LOC','ORG']:\n",
    "        print(ent.text, ent.start_char, ent.end_char,\n",
    "          ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_f1['Text'] = blog_f1['text']\n",
    "blog_f1 = blog_f1[['Text','Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_sentences = []\n",
    "indexes = []\n",
    "for index, row in blog_f1.iterrows():\n",
    "    sentences = tokenizer.tokenize(row.Text) \n",
    "    blog_sentences.extend(sentences)\n",
    "    thisin = [index] * len(sentences)\n",
    "    indexes.extend(thisin)\n",
    "    \n",
    "blog_sent_f = pd.DataFrame(\n",
    "    {'Text': blog_sentences,\n",
    "     'Index': indexes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_sent_f['Label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34033, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_sent_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_sent_f.to_csv(\"../Dataset_v3/blog/blog_2000_sent.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
